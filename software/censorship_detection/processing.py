# process the large datasets using threading 
# solving the issue of loading in the large dataset since files contain very large datasets which would slow the program down 
# so we utilize the minibatch processing getting small data sets from all files in extracted 

# progress.json file has the progress of each file based on the last gotten batch